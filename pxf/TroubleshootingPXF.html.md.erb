---
title: Troubleshooting PXF
---

The following table describes some common errors while using PXF:

<span class="tablecap">Table 1. PXF Errors and Explanation</span>
Error
Common Explanation
ERROR:  invalid URI pxf://localhost:51200/demo/file1: missing options section
`LOCATION` does not include options after the file name: `<path>?<key>=<value>&<key>=<value>...`
ERROR:  protocol "pxf" does not exist
HAWQ is not compiled with PXF protocol. It requires the GPSQL version of HAWQ
ERROR:  remote component error (0) from '&lt;x&gt;': There is no pxf servlet listening on the host and port specified in the external table url.
Wrong server or port, or the service is not started
ERROR:  Missing FRAGMENTER option in the pxf uri: pxf://localhost:51200/demo/file1?a=a
No `FRAGMENTER` option was specified in `LOCATION`.
ERROR:  remote component error (500) from '&lt;x&gt;':   type  Exception report   message   org.apache.hadoop.mapred.InvalidInputException:
Input path does not exist: hdfs://0.0.0.0:8020/demo/file1  

File or pattern given in `LOCATION` doesn't exist on specified path.
ERROR: remote component error (500) from '&lt;x&gt;':   type  Exception report   message   org.apache.hadoop.mapred.InvalidInputException : Input Pattern hdfs://0.0.0.0:8020/demo/file\* matches 0 files 
File or pattern given in `LOCATION` doesn't exist on specified path.
ERROR:  remote component error (500) from '&lt;x&gt;': PXF not correctly installed in CLASSPATH
Cannot find PXF Jar
ERROR:  PXF API encountered a HTTP 404 error. Either the PXF service (tomcat) on data node was not started or PXF webapp was not started.
Either the required data node does not exist or PXF service (tcServer) on data node is not started or PXF webapp was not started
ERROR:  remote component error (500) from '&lt;x&gt;':  type  Exception report   message   java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/client/HTableInterface
One of the classes required for running PXF or one of its plugins is missing. Check that all resources in the PXF classpath files exist on the cluster nodes
ERROR: remote component error (500) from '&lt;x&gt;':   type  Exception report   message   java.io.IOException: Can't get Master Kerberos principal for use as renewer
Secure PXF: YARN isn't properly configured for secure (Kerberized) HDFS installs
ERROR: fail to get filesystem credential for uri hdfs://&lt;namenode&gt;:8020/
Secure PXF: Wrong HDFS host or port is not 8020 (this is a limitation that will be removed in the next release)
ERROR: remote component error (413) from '&lt;x&gt;': HTTP status code is 413 but HTTP response string is empty
The PXF table number of attributes and their name sizes are too large for tcServer to accommodate in its request buffer. The solution is to increase the value of the maxHeaderCount and maxHttpHeaderSize parameters on server.xml on tcServer instance on all nodes and then restart PXF:
&lt;Connector acceptCount="100" connectionTimeout="20000" executor="tomcatThreadPool" maxKeepAliveRequests="15"maxHeaderCount="&lt;some larger value&gt;"maxHttpHeaderSize="&lt;some larger value in bytes&gt;" port="${bio.http.port}" protocol="org.apache.coyote.http11.Http11Protocol" redirectPort="${bio.https.port}"/&gt;

ERROR: remote component error (500) from '&lt;x&gt;': type Exception report message java.lang.Exception: Class com.pivotal.pxf.&lt;plugin name&gt; does not appear in classpath. Plugins provided by PXF must start with "org.apache.hawq.pxf"
Querying a PXF table that still uses the old package name ("com.pivotal.pxf.\*") results in an error message that recommends moving to the new package name ("org.apache.hawq.pxf"). See [Renamed Package Reference](PXFExternalTableandAPIReference.html#topic_b44_yw4_c5).
**HBase Specific Errors**
ERROR:  remote component error (500) from '&lt;x&gt;':   type  Exception report   message    org.apache.hadoop.hbase.client.NoServerForRegionException: Unable to find region for t1,,99999999999999 after 10 tries.
HBase service is down, probably HRegionServer
ERROR:  remote component error (500) from '&lt;x&gt;':  type  Exception report   message   org.apache.hadoop.hbase.TableNotFoundException: nosuch
HBase cannot find the requested table
ERROR:  remote component error (500) from '&lt;x&gt;':  type  Exception report   message   java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/client/HTableInterface
PXF cannot find a required JAR file, probably HBase's
ERROR:  remote component error (500) from '&lt;x&gt;':   type  Exception report   message   java.lang.NoClassDefFoundError: org/apache/zookeeper/KeeperException
PXF cannot find ZooKeeper's JAR
ERROR:  remote component error (500) from '&lt;x&gt;':  type  Exception report   message   java.lang.Exception: java.lang.IllegalArgumentException: Illegal HBase column name a, missing :
PXF table has an illegal field name. Each field name must correspond to an HBase column in the syntax &lt;column family&gt;:&lt;field name&gt;
ERROR: remote component error (500) from '&lt;x&gt;': type Exception report message org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family a does not exist in region t1,,1405517248353.85f4977bfa88f4d54211cb8ac0f4e644. in table 't1', {NAME =&gt; 'cf', DATA\_BLOCK\_ENCODING =&gt; 'NONE', BLOOMFILTER =&gt; 'ROW', REPLICATION\_SCOPE =&gt; '0', COMPRESSION =&gt; 'NONE', VERSIONS =&gt; '1', TTL =&gt; '2147483647', MIN\_VERSIONS =&gt; '0', KEEP\_DELETED\_CELLS =&gt; 'false', BLOCKSIZE =&gt; '65536', ENCODE\_ON\_DISK =&gt; 'true', IN\_MEMORY =&gt; 'false', BLOCKCACHE =&gt; 'true'}
Required HBase table does not contain the requested column
`Hive Specific Errors`
ERROR:  remote component error (500) from '&lt;x&gt;':  type  Exception report   message   java.lang.RuntimeException: Failed to connect to Hive metastore: java.net.ConnectException: Connection refused
Hive Metastore service is down
ERROR:  remote component error (500) from '&lt;x&gt;': type  Exception report   message
NoSuchObjectException(message:default.players table not found)

Table doesn't exist in Hive


