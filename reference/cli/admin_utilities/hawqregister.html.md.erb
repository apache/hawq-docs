---
title: hawq register
---

Registers a parquet-formatted table from an HDFS system into a corresponding table in HAWQ.

## <a id="topic1__section2"></a>Synopsis

``` pre
hawq register [-h <hostname>] [-p <port>] [-U <username>] <databasename> <tablename> <hdfspath> 

hawq register help
hawq register -? 

hawq register --version
```

## <a id="topic1__section3"></a>Prerequisites

The client machine where `hawq register` is executed must have the following:

-   Network access to and from all hosts in your HAWQ cluster (master and segments).
-   Network access to and from the hosts where the data to be loaded resides (ETL servers).
-   The files to be registered and the HAWQ table located in the same HDFS cluster.
-   The target table is configured with the correct data type mapping.

## <a id="topic1__section4"></a>Description

`hawq register` is a utility that loads and registers parquet data in HDFS into HAWQ, so that it can be directly accessed through HAWQ. Table data from the file or directory in the specified path is loaded into the appropriate table directory in HAWQ and the utility updates the corresponding metadata for the files. The table need not contain data.

Only parquet tables can be loaded using the `hawq register` command. Metadata for the parquet file(s) and the destination table must be consistent. Different  data types are used by HAWQ tables and parquet tables, so the data is mapped. You must verify that the structure of the parquet files and the HAWQ table are compatible before running `hawq register`. 

Note: only parquet files generated by HIVE or HAWQ are currently supported.

###Limitations for Registering Hive Tables to HAWQ
The currently-supported data types for generating Hive tables into HAWQ tables are: boolean, int, smallint, tinyint, bigint, float, double, string, binary, char, and varchar.  

The following HIVE data types cannot be converted to HAWQ equivalents: timestamp, decimal, array, struct, map, and union.   


## <a id="topic1__section5"></a>Options

<span class="tablecap">Table 1. General Options</span>

| Option| Description |
| ----  | ----- |
|-? (show help)   |Show help, then exit.|
|-\\\-version  | Show the version of this utility, then exit.|


<span class="tablecap">Table 2. Connection Options</span>

| Option| Description |
| ----  | ----- |
|-h *hostname* | Specifies the host name of the machine on which the HAWQ master database server is running. If not specified, reads from the environment variable `$PGHOST` or defaults to `localhost`.|
| -p *port*  |Specifies the TCP port on which the HAWQ master database server is listening for connections. If not specified, reads from the environment variable `$PGPORT` or defaults to 5432.|
|-U *username*  |The database role name to connect as. If not specified, reads from the environment variable `$PGUSER` or defaults to the current system user name.|
|*databasename*  |The database to register the parquet HDFS data into. |
|*tablename*  |The HAWQ table that will store the parquet data. The table cannot use hash distribution. |
|*hdfspath*|The path of the file or directory containing the files to be registered.|


## <a id="topic1__section6"></a>Examples

This example shows how to register a HIVE-generated parquet file in HDFS into the table `parquet_table` in HAWQ, which is in the database named `postgres`. The file path of the HIVE-generated file is `hdfs://localhost:8020/temp/hive.paq`.

For the purposes of this example, assume that the location of the database is `hdfs://localhost:8020/hawq_default`, the tablespace id is 16385, the database id is 16387, the table filenode id is 77160, and the last file under the filenode is numbered 7.

Enter:

``` pre
$ hawq register postgres parquet_table hdfs://localhost:8020/temp/hive.paq
```

After running the `hawq register` command for the file location  `hdfs://localhost:8020/temp/hive.paq`, the corresponding new location of the file in HDFS is:  `hdfs://localhost:8020/hawq_default/16385/16387/77160/8`. The command then updates the metadata of the table `parquet_table` in HAWQ, which is contained in the table `pg_aoseg.pg_paqseg_77160`. The pg\_aoseg is a fixed schema for row-oriented and parquet ao tables. For row-oriented tables, table name prefix is pg\_aoseg. The table name prefix for parquet tables is pg\_paqseg. 77160 is the relation id of the table.

To locate the table, you can either find the relation ID by looking up the catalog table pg\_class by running `select oid from pg_class where relname=$relname` or by finding the table name by using the command `select segrelid from pg_appendonly where relid = $relid` then running `select relname from pg_class where oid = segrelid`.

##Data Type Mapping<a id="topic1__section7"></a>

Different data types are used by HAWQ and parquet format tables and by HIVE and HAWQ tables. Mapping must be used for compatibility. You are responsible for making sure your implementation is mapped to the appropriate data type before running `hawq register`. The tables below show equivalent data types, if available.

<span class="tablecap">Table 3. HAWQ to Parquet Mapping</span>

|HAWQ Data Type   | Parquet Data Type  |
| :------------| :---------------|
| bool        | boolean       |
| int2/int4/date        | int32       |
| int8/money       | int64      |
| time/timestamptz/timestamp       | int64      |
| float4        | float       |
|float8        | double       |
|bit/varbit/bytea/numeric       | Byte array       |
|char/bpchar/varchar/name| Byte array |
| text/xml/interval/timetz  | Byte array  |
| macaddr/inet/cidr  | Byte array  |

**Additional HAWQ-to-Parquet Mapping**

**point**:  

``` 
group {
    required int x;
    required int y;
}
```

**circle:** 

```
group {
    required int x;
    required int y;
    required int r;
}
```

**box:**  

```
group {
    required int x1;
    required int y1;
    required int x2;
    required int y2;
}
```

**iseg:** 


```
group {
    required int x1;
    required int y1;
    required int x2;
    required int y2;
}
``` 

**path**:
  
```
group {
    repeated group {
        required int x;
        required int y;
    }
}
```


<span class="tablecap">Table 3. HIVE to HAWQ Mapping</span>

|HIVE Data Type   | HAWQ Data Type  |
| :------------| :---------------|
| boolean        | bool       |
| tinyint        | int2       |
| smallint       | int2/smallint      |
| int            | int4 / int |
| bigint         | int8 / bigint      |
| float        | float8 / double precision       |
| string        | varchar       |
| binary      | bytea       |
| char | char |
| varchar  | varchar  |




