---
title: Select HAWQ Host Machines
---

<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->

Before you begin to install HAWQ, follow these steps to select and prepare the host machines.

Complete this procedure for all HAWQ deployments:

1.  **Choose the host machines that will host a HAWQ segment.** Keep in mind these restrictions and requirements:
    -   Each host must meet the system requirements for the version of HAWQ you are installing.
    -   Each HAWQ segment must be co-located on a host that runs an HDFS DataNode.
    -   The HAWQ master segment and standby master segment must be hosted on separate machines.
2.  **Choose the host machines that will run PXF.** Keep in mind these restrictions and requirements:
    -   PXF must be installed on the HDFS NameNode *and* on all HDFS DataNodes.
    -   If you have configured Hadoop with high availability, PXF must also be installed on all HDFS nodes including all NameNode services.
    -   If you want to use PXF with HBase or Hive, you must first install the HBase client \(hbase-client\) and/or Hive client \(hive-client\) on each machine where you intend to install PXF. See the [HDP installation documentation](https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/index.html) for more information.
3.  **Verify that required ports on all machines are unused.** By default, a HAWQ master or standby master service configuration uses port 5432. Hosts that run other PostgreSQL instances cannot be used to run a default HAWQ master or standby service configuration because the default PostgreSQL port \(5432\) conflicts with the default HAWQ port. You must either change the default port configuration of the running PostgreSQL instance or change the HAWQ master port setting during the HAWQ service installation to avoid port conflicts.
    
    **Note:** The Ambari server node uses PostgreSQL as the default metadata database. The Hive Metastore uses MySQL as the default metadata database.